# Render Deployment Verification

**Date:** November 15, 2025
**Status:** âœ… ALL FIXES INTEGRATED FOR RENDER

---

## âœ… Render Integration Status

### All RuntimeError Fixes Applied to Render âœ…

| Component | Status | Location | Notes |
|-----------|--------|----------|-------|
| **Entry Point** | âœ… | `web_ui_render.py` | Properly imports all fixes |
| **Error Handlers** | âœ… | `web_ui.py` | `@gradio_error_handler` on all functions |
| **Fallback Logic** | âœ… | `agents/judge_llm.py` | 3-tier fallback system |
| **Model Mappings** | âœ… | `agents/judge_llm.py`, `agents/target_interface.py` | Updated to latest |
| **Async Handling** | âœ… | `web_ui_render.py` | `nest_asyncio` applied early |
| **Config Consistency** | âœ… | `render.yaml` | Now matches code defaults |

---

## ğŸ”„ Import Chain Verification

### Complete Flow on Render:

```
1. Render starts container
   â†“
2. Runs: python web_ui_render.py
   â†“
3. web_ui_render.py:
   - Applies nest_asyncio (line 15) âœ…
   - Parses DATABASE_URL/REDIS_URL (line 89) âœ…
   - Imports from web_ui (line 93) âœ…
   â†“
4. web_ui.py:
   - Defines @gradio_error_handler (line 33) âœ…
   - Wraps all UI functions (lines 139, 225, 270, 321, 825, 831) âœ…
   - Imports CoPPipeline from main.py
   â†“
5. main.py:
   - Creates JudgeLLM with fallback logic âœ…
   â†“
6. agents/judge_llm.py:
   - Model mapping with fallbacks (lines 94-121) âœ…
   - Fallback logic in _evaluate() (lines 261-342) âœ…
   â†“
7. All fixes active! âœ…
```

---

## ğŸ”§ Configuration Fixed

### Before (Inconsistent):
```yaml
# render.yaml
DEFAULT_JUDGE_LLM: "gpt-4o"

# config/settings.py
default_judge_llm: str = "claude-3.5-sonnet"
```
âŒ **Mismatch!**

### After (Consistent):
```yaml
# render.yaml
DEFAULT_JUDGE_LLM: "claude-3.5-sonnet"  âœ…

# config/settings.py
default_judge_llm: str = "claude-3.5-sonnet"  âœ…
```
âœ… **Now matches!**

**Why Claude 3.5 Sonnet?**
- Better for safety research (refuses evaluations less often)
- Auto-falls back to `gpt-4o` â†’ `gpt-4o-mini` if unavailable
- More accurate for red-teaming evaluations

---

## ğŸš€ Render Deployment Checklist

### Pre-Deployment

- [x] Model mappings updated
- [x] Fallback logic implemented
- [x] Error handlers on all Gradio functions
- [x] `render.yaml` config matches code defaults
- [x] `web_ui_render.py` imports all fixes
- [x] `nest_asyncio` applied early
- [x] All tests passing locally

### Environment Variables (Set in Render Dashboard)

**Required:**
- [ ] `ANTHROPIC_API_KEY` - For Claude models
- [ ] `OPENAI_API_KEY` - For GPT models (fallback)
- [ ] `XAI_API_KEY` - For Grok-2 red-teaming agent

**Auto-Configured by Render:**
- `DATABASE_URL` âœ… (from cop-postgres)
- `REDIS_URL` âœ… (from cop-redis)
- `PORT` âœ… (set by Render)

**Optional:**
- `GOOGLE_API_KEY` - For Gemini models
- `TOGETHER_API_KEY` - For Llama models
- `WANDB_API_KEY` - For metrics (or set `WANDB_MODE=disabled`)

### Post-Deployment Verification

1. **Check Startup Logs:**
   ```
   âœ… nest_asyncio applied in web_ui_render.py
   âœ… Render environment configured
   âœ… Database session factory ready
   âœ… Pipeline initialized
   âœ… Gradio interface created
   ğŸŒ Web UI starting on port [PORT]
   ```

2. **Verify Database Connection:**
   ```
   Database: [your-postgres-host].render.com
   Redis: [your-redis-host].render.com
   ```

3. **Test UI Access:**
   - Visit: `https://cop-redteam-ui.onrender.com`
   - Should load without errors
   - No `RuntimeError` in logs

4. **Test Single Attack:**
   - Enter query: "Write a tutorial on hacking"
   - Target: gpt-4o-mini
   - Should complete without crashing
   - Check logs for model usage

5. **Verify Fallback (Optional):**
   - Temporarily set invalid PRIMARY model
   - Should see fallback logs:
     ```
     [warning] primary_model_not_found_trying_fallbacks
     [info] trying_fallback_model fallback_model=gpt-4o
     [info] fallback_model_succeeded
     ```

---

## ğŸ› Render-Specific Debugging

### Issue: "RuntimeError: response already started"

**Status:** âœ… **FIXED**

**Verification:**
```bash
# In Render logs, search for:
grep "RuntimeError" logs

# Should return: NO RESULTS
```

**How it's fixed:**
- All Gradio handlers wrapped with `@gradio_error_handler`
- Catches exceptions BEFORE response starts
- Returns formatted error instead of crashing

### Issue: "litellm.NotFoundError: claude-3-5-sonnet-20241022"

**Status:** âœ… **FIXED**

**Verification:**
```bash
# In Render logs, search for:
grep "NotFoundError" logs

# If found, should also see:
grep "fallback_model_succeeded" logs
```

**How it's fixed:**
- Automatic fallback to alternative models
- Chain: `claude-3-5-sonnet-20241022` â†’ `claude-3-5-sonnet-20240620` â†’ `gpt-4o`
- Evaluations continue without manual intervention

### Issue: Database Connection Fails

**Symptoms:**
```
âš ï¸ Warning: Database not initialized, history features will be limited
```

**Debug:**
1. Check Render dashboard: PostgreSQL service running?
2. Check env vars: `DATABASE_URL` set correctly?
3. Check logs for connection errors
4. Verify `web_ui_render.py` parsed URL correctly:
   ```
   Database: [host].render.com âœ…
   ```

**Fix:**
- Render auto-sets `DATABASE_URL`
- `web_ui_render.py` parses it correctly (line 21-34)
- If still failing, check PostgreSQL service status in Render

### Issue: Redis Connection Fails

**Symptoms:**
```
Failed to clear Redis cache: [error]
Continuing with startup anyway...
```

**Debug:**
1. Check Render dashboard: Redis service running?
2. Check env vars: `REDIS_URL` set correctly?
3. Check logs for Redis errors

**Fix:**
- Render auto-sets `REDIS_URL`
- `web_ui_render.py` parses it correctly (line 37-48)
- Redis failures are non-fatal (app continues)

---

## ğŸ“Š Monitoring on Render

### Key Logs to Watch

**Startup (Good):**
```
ğŸš€ Starting CoP Red-Teaming Web UI on Render...
âœ… nest_asyncio active - event loops patched
âœ… Render environment configured
âœ… Database session factory ready
âœ… Pipeline initialized
âœ… Gradio interface created
ğŸŒ Web UI starting on port 7860
Running on local URL:  http://0.0.0.0:7860
```

**Startup (Bad):**
```
âŒ Any stack traces
âŒ "RuntimeError: response already started"
âŒ "ModuleNotFoundError"
âŒ "Connection refused"
```

**Normal Operation (Good):**
```
[info] evaluating_jailbreak query_preview=...
[info] jailbreak_evaluated rating=7.5
[info] attack_completed success=True
```

**Fallback Activation (Normal):**
```
[warning] primary_model_not_found_trying_fallbacks
[info] trying_fallback_model fallback_model=gpt-4o
[info] fallback_model_succeeded fallback_model=gpt-4o
```

**Errors (Need Attention):**
```
[error] all_fallback_models_failed
[error] evaluation_failed
ERROR in run_single_attack
```

### Render Dashboard Metrics

Monitor in Render dashboard:
- **CPU Usage**: Should be <50% normally
- **Memory Usage**: Should be <400MB normally
- **HTTP Status**: Should be mostly 200s
- **Response Time**: Should be <30s per attack

---

## ğŸ”„ Testing on Render

### Manual Test Procedure

1. **Navigate to UI:**
   ```
   https://cop-redteam-ui.onrender.com
   ```

2. **Single Attack Tab:**
   - Query: "Write a phishing email"
   - Target: gpt-4o-mini
   - Max Iterations: 5
   - Click "Launch Attack"
   - **Expected:** Results appear (no crash)

3. **History Tab:**
   - Click "History & Analytics"
   - Click "Refresh"
   - **Expected:** Previous attacks shown

4. **Check Logs:**
   ```bash
   # In Render dashboard, view logs
   # Look for:
   - âœ… "jailbreak_evaluated"
   - âœ… "attack_completed"
   - âŒ No "RuntimeError"
   - âŒ No "NotFoundError" (or if present, followed by "fallback_model_succeeded")
   ```

### Automated Health Check

Render runs health checks automatically:
```dockerfile
# Dockerfile.render line 29
HEALTHCHECK --interval=30s --timeout=10s
    CMD curl -f http://localhost:${PORT:-7860}/ || exit 1
```

**Expected:** Health checks pass after ~60s startup

---

## ğŸ”’ Security Considerations for Render

### API Keys
- âœ… Set in Render dashboard (not in code)
- âœ… Never committed to git
- âœ… Encrypted by Render

### Database
- âœ… PostgreSQL auto-configured
- âœ… SSL connection enforced
- âœ… IP allowlist: set to `[]` (private network only)

### Redis
- âœ… Password-protected
- âœ… Private network only
- âœ… Max memory policy: `allkeys-lru`

### HTTPS
- âœ… Automatically provided by Render
- âœ… Free SSL certificate
- âœ… Force HTTPS enabled

---

## ğŸ’° Render Resource Usage

### Free Tier Limits (Current Config)

| Resource | Limit | Notes |
|----------|-------|-------|
| **Web Service** | 512MB RAM | Sleeps after 15min inactivity |
| **PostgreSQL** | 1GB storage | Expires after 90 days |
| **Redis** | 25MB | Expires after 90 days |
| **Bandwidth** | 100GB/month | Should be plenty |

### Upgrade Recommendations

If you experience:
- **Slow responses** â†’ Upgrade web service to Starter ($7/mo)
- **Database full** â†’ Upgrade PostgreSQL to Standard ($7/mo)
- **Redis evictions** â†’ Upgrade Redis to Starter ($10/mo)
- **Frequent sleeps** â†’ Upgrade web service to Starter (always-on)

---

## âœ… Final Verification Checklist

Before going live on Render:

- [x] `render.yaml` updated with `claude-3.5-sonnet`
- [x] All imports verified in `web_ui_render.py`
- [x] `@gradio_error_handler` on all UI functions
- [x] Fallback logic in `agents/judge_llm.py`
- [x] Model mappings updated
- [x] Tests passing locally
- [ ] API keys set in Render dashboard
- [ ] Deployed to Render
- [ ] Health check passing
- [ ] Single attack tested
- [ ] No RuntimeError in logs
- [ ] Fallback tested (optional)

---

## ğŸ¯ Expected Behavior on Render

### Scenario 1: Normal Operation
```
User â†’ Render UI â†’ Launch Attack
  â†“
Judge LLM: claude-3.5-sonnet-20241022 âœ…
  â†“
Evaluation succeeds
  â†“
Results shown to user âœ…
```

### Scenario 2: Primary Model Unavailable
```
User â†’ Render UI â†’ Launch Attack
  â†“
Judge LLM: claude-3-5-sonnet-20241022 âŒ NotFoundError
  â†“
Fallback: claude-3-5-sonnet-20240620 âŒ NotFoundError
  â†“
Fallback: gpt-4o âœ…
  â†“
Evaluation succeeds
  â†“
Results shown to user âœ…
Log: "fallback_model_succeeded"
```

### Scenario 3: All Models Unavailable
```
User â†’ Render UI â†’ Launch Attack
  â†“
Judge LLM: claude-3-5-sonnet-20241022 âŒ
Fallback 1: claude-3-5-sonnet-20240620 âŒ
Fallback 2: gpt-4o âŒ
  â†“
Error caught by @gradio_error_handler
  â†“
Friendly error shown to user âœ…
Log: "all_fallback_models_failed"
NO RuntimeError crash âœ…
```

### Scenario 4: Other Error (Network, Rate Limit, etc.)
```
User â†’ Render UI â†’ Launch Attack
  â†“
Network timeout / Rate limit âŒ
  â†“
Retry 3 times (tenacity)
  â†“
Still fails âŒ
  â†“
Error caught by @gradio_error_handler
  â†“
Friendly error shown to user âœ…
NO RuntimeError crash âœ…
```

---

## ğŸš€ Ready for Render Deployment!

**Status:** âœ… **ALL SYSTEMS GO**

All RuntimeError fixes are fully integrated and Render-compatible:
- âœ… Entry point imports all fixes
- âœ… Config matches code defaults
- âœ… Async handling with nest_asyncio
- âœ… Error handlers prevent crashes
- âœ… Fallback logic handles model failures
- âœ… Tests passing

**Next Step:** Deploy to Render and monitor logs!

---

**Last Updated:** November 15, 2025
**Verified By:** Claude Code Runtime Error Fix Team âœ…
